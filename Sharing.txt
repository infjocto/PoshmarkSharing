# PoshmarkSharing
# Objective: Shares items from closet to followers

##########################################################
# SETUP
pip install selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

# OPENING BROWSER TO PAGE
browser = webdriver.Chrome('C:\\webdrivers\chromedriver.exe')
# Page with all available listings
browser.get('https://poshmark.com/closet/muselet?department=Women&availability=available')

# SHARING LISTINGS ########################################

# 1st
elem = browser.find_element_by_xpath('/html/body/main/div[5]/section/div[4]/div[3]/div[1]/div/div[2]/ul/li[3]')
elem.click() # clicking share button on page
time.sleep(3)
elem = browser.find_element_by_xpath('/html/body/main/div[5]/section/div[4]/div[4]/div[2]/div/div[2]/ul/li[1]/a')
elem.click() # clicking 2nd share button on popup
print('1st listing shared.')
time.sleep(5)
# 2nd
elem = browser.find_element_by_xpath('/html/body/main/div[5]/section/div[4]/div[3]/div[2]/div/div[2]/ul/li[3]')
elem.click()
elem = browser.find_element_by_xpath('/html/body/main/div[5]/section/div[4]/div[4]/div[2]/div/div[2]/ul/li[1]/a')
elem.click()
print("2nd Listing shared.")

# 4th

elem = browser.find_element_by_xpath('/html/body/main/div[5]/section/div[4]/div[3]/div[4]/div/div[2]/ul/li[3]')
elem.click()

elem = browser.find_element_by_xpath('/html/body/main/div[5]/section/div[4]/div[4]/div[2]/div/div[2]/ul/li[1]/a')
elem.click()

# 8th

elem = browser.find_element_by_xpath('/html/body/main/div[3]/section/div[4]/div[2]/div[8]/div/div[2]/ul/li[3]')
elem.click()

elem = browser.find_element_by_xpath('/html/body/main/div[5]/section/div[4]/div[4]/div[2]/div/div[2]/ul/li[1]/a')
elem.click()


# last listing

elem = browser.find_element_by_cs('#\35 ccf251ca20dfcb51377cb43-listing-actions > li:nth-child(3) > a')
elem.click()

elem = browser.find_element_by_xpath('/html/body/main/div[5]/section/div[4]/div[4]/div[2]/div/div[2]/ul/li[1]/a')
elem.click()

## ALTERNATE METHODS THAT WORK
# find_element_by_class_name # clicks first share button on page
browser.find_element_by_class_name('share').click()

# MAIN METHOD : xpath and why it's the best
# Depending on how you name it. you want to use a reference that won't break even if the HTML is slightly changed


# GENERALIZE SHARING
# sharing by product number and share button 
elem = browser.find_element_by_xpath("//a[@class='share'][@data-pa-attr-listing_id='5dbb227e7f617f29b0029d7e']")

elem.click()
# generalizing 2nd pop up button
browser.find_element_by_xpath('//div[@class='share-wrapper-con']')
xpath: //*[@id="5dbb227e7f617f29b0029d7e-listing-actions"]/li[3]/a
fullx: /html/body/main/div[5]/section/div[4]/div[3]/div[5]/div/div[2]/ul/li[3]/a
#=============================================================================
## Input LOGIN AND PASSWORD SECTION

browser.get('https://poshmark.com/login')

# input password and username, click enter
usernameBar = browser.find_element_by_id('login_form_username_email')
unn = input("Username:") #stores your response into this unn variable
usernameBar.send_keys(unn) #enters your input in the the usernameBar field
passwordBar = browser.find_element_by_id('login_form_password')
pww = input("Password:")
passwordBar.send_keys(pww)

from selenium.webdriver.common.keys import Keys #importing common keyboard keys
passwordBar.send_keys('Keys.ENTER') # presses enter
#================================================================================

## WEBSCRAPING LISTING id

pip.main(["install", "bs4"])
# beautifulsoup parses HTML
from bs4 import BeautifulSoup
pip.main(["install", "requests"])
# requests, in this case, helps us get HTML from URL
import requests
poshlink = 'https://poshmark.com/closet/muselet?department=Women&availability=available' # Specify url to be web-scraped

# load html data - webscrape
page = requests.get(poshlink)
time.sleep(10)
stat = page.status_code
time.sleep(10)
if str(stat)[0] == "2":
  ## if 200 or starts with 2, then it has completed
  print("Scraping Complete.")
else:
  print("Error...")

  # Parse the html and store it in Beautiful Soup format
soup = BeautifulSoup(page.content, 'html.parser')
time.sleep(10)
# Look at the nested structure of the html page
print(soup.prettify())

# Extracting product's HTML section using product ID
all_items = soup.find_all('div', class_="a-section a-spacing-none g-item-sortable")
## all_items is a "bs4.element.ResultSet", with each index pertaining to a different product
## by converting each index in all_item into a list --> list(all_items[0]), you can extract relevant info
### DO NOT convert all_items into a list, it will be too messy
all_items[0]